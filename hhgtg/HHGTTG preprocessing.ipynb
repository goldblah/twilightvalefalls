{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import textblob\n",
    "import collections\n",
    "from textblob import Word\n",
    "from textblob.tokenizers import WordTokenizer\n",
    "from spellchecker import SpellChecker\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "import time\n",
    "from pycontractions import Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = Contractions(api_key=\"glove-twitter-25\")\n",
    "cont.load_models()\n",
    "\n",
    "def contract_handle(st):\n",
    "    #print('Doing text %d...' %texts.index(st))\n",
    "    t = list(cont.expand_texts([st.replace(\"â€™\",\"'\")]))[0]\n",
    "    tags = nltk.pos_tag(word_tokenize(str(t)))\n",
    "    temp = []\n",
    "    print('%d tags created...' %len(tags))\n",
    "    for tag in tags:\n",
    "        temp.append(tag[0])\n",
    "            \n",
    "    return ' '.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting the scripts and titles fo each episode into lists\n",
    "script_list = []\n",
    "title_list = []\n",
    "# grabbing named entities\n",
    "with open('fixed_named_entity_hhgttg.txt', 'r', encoding='utf-8') as myfile:\n",
    "    ner = myfile.read()\n",
    "\n",
    "# actually adding the scripts and episode titles to their respective lists with some cleaning\n",
    "for i in os.listdir('hhgttg'):\n",
    "    with open('hhgttg/' + i, 'r', encoding='utf-8') as myfile:\n",
    "        script_list.append(myfile.read().replace('\\n',' ').lower())\n",
    "        title_list.append(i.replace('_',' ').replace('.txt',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#throwing everything into a dataframe\n",
    "data = {'Source': \"Hitchhiker's Guide to the Galaxy\", \n",
    "        'Title': \"Hitchhiker's Guide to the Galaxy\", \n",
    "        'Date': 'October 12, 1979', \n",
    "        'Text': script_list}\n",
    "hh = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57624 tags created...\n"
     ]
    }
   ],
   "source": [
    "# using pycontractions to expand contractions\n",
    "contractions = contract_handle(str(list(hh['Text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the text to the expanded text\n",
    "hh['Text'] = contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sending dataframe to csv\n",
    "#hh.to_csv(path_or_buf=('C:\\\\Users\\\\ced4689\\\\Desktop\\\\TVF'),sep=('|'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
