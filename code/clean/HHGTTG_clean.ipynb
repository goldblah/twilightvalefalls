{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import textblob\n",
        "import collections\n",
        "from textblob import Word\n",
        "from textblob.tokenizers import WordTokenizer\n",
        "from spellchecker import SpellChecker\n",
        "from bs4 import BeautifulSoup\n",
        "from requests import get\n",
        "from requests.exceptions import RequestException\n",
        "from contextlib import closing\n",
        "import time\n",
        "from pycontractions import Contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "cont \u003d Contractions(api_key\u003d\"glove-twitter-25\")\n",
        "cont.load_models()\n",
        "\n",
        "def contract_handle(st):\n",
        "    #print(\u0027Doing text %d...\u0027 %texts.index(st))\n",
        "    t \u003d list(cont.expand_texts([st.replace(\"’\",\"\u0027\")]))[0]\n",
        "    tags \u003d nltk.pos_tag(word_tokenize(str(t)))\n",
        "    temp \u003d []\n",
        "    print(\u0027%d tags created...\u0027 %len(tags))\n",
        "    for tag in tags:\n",
        "        temp.append(tag[0])\n",
        "            \n",
        "    return \u0027 \u0027.join(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "# getting the scripts and titles fo each episode into lists\nscript_list \u003d []\ntitle_list \u003d []\n# grabbing named entities\nwith open(\"/volumes/Hayley\u0027s Drive/PycharmProjects/twilightvalefalls/named_entities_all/fixed_named_entity_hhgttg.txt\", \u0027r\u0027, encoding\u003d\u0027utf-8\u0027) as myfile:\n    ner \u003d myfile.read()\n\n# actually adding the scripts and episode titles to their respective lists with some cleaning\nfor i in os.listdir(\"/volumes/Hayley\u0027s Drive/PycharmProjects/twilightvalefalls/hhgtg/\"):\n    if i.endswith(\u0027.txt\u0027):\n        with open(\"/volumes/Hayley\u0027s Drive/PycharmProjects/twilightvalefalls/hhgtg/\" + i, \u0027r\u0027, encoding\u003d\u0027utf-8\u0027) as myfile:\n            script_list.append(myfile.read().replace(\u0027\\n\u0027,\u0027 \u0027).lower())\n            title_list.append(i.replace(\u0027_\u0027,\u0027 \u0027).replace(\u0027.txt\u0027,\u0027\u0027))"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "#throwing everything into a dataframe\n",
        "data \u003d {\u0027Source\u0027: \"Hitchhiker\u0027s Guide to the Galaxy\", \n",
        "        \u0027Title\u0027: \"Hitchhiker\u0027s Guide to the Galaxy\", \n",
        "        \u0027Date\u0027: \u0027October 12, 1979\u0027, \n",
        "        \u0027Text\u0027: script_list}\n",
        "hh \u003d pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-7-3aca959f388c\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# using pycontractions to expand contractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mcontractions\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mcontract_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u0027Text\u0027\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m\u003cipython-input-2-2af7ece7332c\u003e\u001b[0m in \u001b[0;36mcontract_handle\u001b[0;34m(st)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcontract_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(\u0027Doing text %d...\u0027 %texts.index(st))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 6\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"’\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\u0027\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/nlp2/lib/python3.6/site-packages/pycontractions/contractions.py\u001b[0m in \u001b[0;36mexpand_texts\u001b[0;34m(self, texts, precise, scores)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 394\u001b[0;31m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediates\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mintermediates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/nlp2/lib/python3.6/site-packages/pycontractions/contractions.py\u001b[0m in \u001b[0;36m_expand_text\u001b[0;34m(self, text, scores)\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0mtext1\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     hyp.append((text1, self.kv_model.wmdistance(\n\u001b[0;32m--\u003e 342\u001b[0;31m                         text.split(), text1.split()), len(self.lc_tool.check(text1))))\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0mhyp\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0;31m# The text of the first item is most likely correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/nlp2/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mwmdistance\u001b[0;34m(self, document1, document2)\u001b[0m\n\u001b[1;32m    615\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                 \u001b[0;31m# Compute Euclidean distance between word vectors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 617\u001b[0;31m                 \u001b[0mdistance_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_matrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/nlp2/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# allow calls like trained_model[\u0027office\u0027], as a shorthand for trained_model[[\u0027office\u0027]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "source": [
        "# using pycontractions to expand contractions\n",
        "contractions \u003d contract_handle(str(list(hh[\u0027Text\u0027])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "#changing the text to the expanded text\n",
        "hh[\u0027Text\u0027] \u003d contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# sending dataframe to csv\n",
        "#hh.to_csv(path_or_buf\u003d(\u0027C:\\\\Users\\\\ced4689\\\\Desktop\\\\TVF\u0027),sep\u003d(\u0027|\u0027))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
