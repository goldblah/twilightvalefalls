{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import html2text\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import glob\n",
    "import itertools\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "%run scrape.py #functions: simple_get, is_good_response, log_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary for character html\n",
    "wtnv_html_dict_char = dict()\n",
    "main_url = 'https://nightvale.fandom.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull character list\n",
    "char_url = 'https://nightvale.fandom.com/wiki/Category:Characters'\n",
    "\n",
    "tz = simple_get(char_url)\n",
    "time.sleep(1)\n",
    "\n",
    "#parse html\n",
    "html = BeautifulSoup(tz, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get links\n",
    "links = html.findAll(\"a\", {\"class\" : \"category-page__member-link\"})\n",
    "\n",
    "for link in links:\n",
    "    #get page\n",
    "    tz_l = simple_get(main_url+link['href'])\n",
    "    time.sleep(1)\n",
    "    #parse html\n",
    "    html_l = BeautifulSoup(tz_l, 'html.parser')\n",
    "    #follow every episode link\n",
    "    #pull release date, episode num?\n",
    "    name = html_l.find(\"meta\", {\"property\" : \"og:title\"}).get(\"content\")\n",
    "    wtnv_html_dict_char[name] = html_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format all character names\n",
    "ner_char = []\n",
    "for entry in wtnv_html_dict_char:\n",
    "    entry = entry.strip()\n",
    "    if 'Category' not in entry:\n",
    "        div = wtnv_html_dict_char[entry].findAll(\"div\", {\"data-source\" : \"aka\"})\n",
    "        if len(div) > 0:\n",
    "            akas = str(div[0].find(\"div\", {\"class\" : \"pi-data-value pi-font\"}))[35:-6]\n",
    "            sp = ['Chad Bowinger', 'Glow Cloud (ALL HAIL)', 'Janice', 'Old Woman Josie', \n",
    "                  'The Man in the Tan Jacket (character)', 'The Faceless Old Woman (character)', \n",
    "                  'John Peters (you know, the farmer?)']\n",
    "            if entry not in sp:\n",
    "                #deal with the two\n",
    "                en = entry.strip()+\"::CHAR:\"\n",
    "                if len(entry.split(' ')) > 1:\n",
    "                    en = en+entry.strip()[0]+entry.strip().split(' ')[-1]\n",
    "                else:\n",
    "                    en = en+entry.strip()\n",
    "                ner_char.append(en)\n",
    "                en2 = akas.strip()+\"::CHR:\"\n",
    "                if len(entry.strip().split(' ')) > 1:\n",
    "                    en2 = en2+entry.strip()[0]+entry.strip().split(' ')[-1]\n",
    "                else:\n",
    "                    en2 = en2+entry.strip()\n",
    "                ner_char.append(en2)\n",
    "            else:\n",
    "                brack = ['Glow Cloud (ALL HAIL)','John Peters (you know, the farmer?)', \n",
    "                         'The Faceless Old Woman (character)', 'The Man in the Tan Jacket (character)']\n",
    "                if entry in brack:\n",
    "                    ent = entry.strip().replace('(character)','').replace('(ALL HAIL)','').replace('(you know, the farmer?)','').strip()\n",
    "                    ner_char.append(ent+\"::CHR:\"+ent[0]+ent.split(' ')[-1])\n",
    "                    for aka in akas.replace('know,',':').split(\",\"):\n",
    "                        ner_char.append(aka.replace('(All Hail)','').replace('(you : the farmer?)','').strip()+\"::CHR:\"+ent[0]+ent.split(' ')[-1])\n",
    "                else:\n",
    "                    #print(entry)\n",
    "                    l1 = akas.split('<br/>')\n",
    "                    if len(l1) > 1:\n",
    "                        ner_char.append(entry.strip()+\"::CHR:\"+entry.strip()[0]+entry.strip().split(' ')[-1])\n",
    "                        for l in l1:\n",
    "                            ner_char.append(l.strip()+\"::CHR:\"+entry.strip()[0]+entry.strip().split(' ')[-1])\n",
    "                    else:\n",
    "                        l2 = akas.split(',')\n",
    "                        if len(l2) > 1:\n",
    "                            ner_char.append(entry.strip()+\"::CHR:\"+entry.strip()[0]+entry.strip().split(' ')[-1])\n",
    "                            for l in l2:\n",
    "                                ner_char.append(l.strip()+\"::CHR:\"+entry.strip()[0]+entry.strip().split(' ')[-1])\n",
    "                        else:\n",
    "                            ner_char.append(entry.strip()+\"::CHR:\"+entry.strip())\n",
    "                            ner_char.append(akas.split('by')[0].strip()+\"::CHR:\"+entry.strip())\n",
    "\n",
    "        else:\n",
    "            en = entry.strip()+\"::CHR:\"\n",
    "            if len(entry.strip().split(' ')) > 1:\n",
    "                en = en+entry.strip()[0]+entry.strip().split(' ')[-1]\n",
    "            else:\n",
    "                en = en+entry.strip()\n",
    "            ner_char.append(en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape list of creatures\n",
    "wtnv_html_dict_crea = dict()\n",
    "creature_url = 'https://nightvale.fandom.com/wiki/Category:Night_Vale_creatures'\n",
    "\n",
    "tz = simple_get(creature_url)\n",
    "time.sleep(1)\n",
    "\n",
    "#parse html\n",
    "html = BeautifulSoup(tz, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get links\n",
    "links = html.findAll(\"a\", {\"class\" : \"category-page__member-link\"})\n",
    "\n",
    "for link in links:\n",
    "    #get page\n",
    "    tz_l = simple_get(main_url+link['href'])\n",
    "    time.sleep(1)\n",
    "    #parse html\n",
    "    html_l = BeautifulSoup(tz_l, 'html.parser')\n",
    "    \n",
    "    name = html_l.find(\"meta\", {\"property\" : \"og:title\"}).get(\"content\")\n",
    "    wtnv_html_dict_crea[name] = html_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_crea = []\n",
    "for entry in wtnv_html_dict_crea:\n",
    "    entry = entry.replace('(creature)','').strip()\n",
    "    if 'List' not in entry:\n",
    "        if len(entry.strip().split(' ')) > 1:\n",
    "            ner_crea.append(entry+\"::CrAn:\"+entry[0]+entry.split(' ')[-1])\n",
    "        else:\n",
    "            ner_crea.append(entry+\"::CrAn:\"+entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtnv_html_dict_loc = dict()\n",
    "loc_url = 'https://nightvale.fandom.com/wiki/Category:Locations'\n",
    "\n",
    "tz = simple_get(loc_url)\n",
    "time.sleep(1)\n",
    "\n",
    "#parse html\n",
    "html = BeautifulSoup(tz, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get links\n",
    "links = html.findAll(\"a\", {\"class\" : \"category-page__member-link\"})\n",
    "\n",
    "for link in links:\n",
    "    #get page\n",
    "    tz_l = simple_get(main_url+link['href'])\n",
    "    time.sleep(1)\n",
    "    #parse html\n",
    "    html_l = BeautifulSoup(tz_l, 'html.parser')\n",
    "    \n",
    "    name = html_l.find(\"meta\", {\"property\" : \"og:title\"}).get(\"content\")\n",
    "    wtnv_html_dict_loc[name] = html_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_loc = []\n",
    "for entry in wtnv_html_dict_loc:\n",
    "    entry = entry.replace('(town)','').strip()\n",
    "    if (entry[-1] != '2') & ('ocations' not in entry):\n",
    "        ner_loc.append(entry+\"::LOC:\"+entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtnv_html_dict_org = dict()\n",
    "org_urls = ['https://nightvale.fandom.com/wiki/Category:Organization', \n",
    "            'https://nightvale.fandom.com/wiki/Category:Night_Vale_organizations']\n",
    "\n",
    "tz = simple_get(org_urls[0])\n",
    "time.sleep(1)\n",
    "\n",
    "#parse html\n",
    "html = BeautifulSoup(tz, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get links\n",
    "links = html.findAll(\"a\", {\"class\" : \"category-page__member-link\"})\n",
    "\n",
    "for link in links:\n",
    "    #get page\n",
    "    tz_l = simple_get(main_url+link['href'])\n",
    "    time.sleep(1)\n",
    "    #parse html\n",
    "    html_l = BeautifulSoup(tz_l, 'html.parser')\n",
    "    \n",
    "    name = html_l.find(\"meta\", {\"property\" : \"og:title\"}).get(\"content\")\n",
    "    wtnv_html_dict_org[name] = html_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz = simple_get(org_urls[1])\n",
    "time.sleep(1)\n",
    "\n",
    "#parse html\n",
    "html = BeautifulSoup(tz, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get links\n",
    "links = html.findAll(\"a\", {\"class\" : \"category-page__member-link\"})\n",
    "\n",
    "for link in links:\n",
    "    #get page\n",
    "    tz_l = simple_get(main_url+link['href'])\n",
    "    time.sleep(1)\n",
    "    #parse html\n",
    "    html_l = BeautifulSoup(tz_l, 'html.parser')\n",
    "    \n",
    "    name = html_l.find(\"meta\", {\"property\" : \"og:title\"}).get(\"content\")\n",
    "    wtnv_html_dict_org[name] = html_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_org = []\n",
    "for entry in wtnv_html_dict_org:\n",
    "    ner_org.append(entry+\"::ORG:\"+entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = ner_loc+ner_org+ner_char+ner_crea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wtnv_ner.txt', 'w') as f:\n",
    "    for item in li:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
